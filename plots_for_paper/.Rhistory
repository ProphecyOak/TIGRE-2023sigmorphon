dat.errors <- read.csv("data/fra_error_distribution.csv")
dat.err.long <- dat.errors %>%
pivot_longer(!Data.set, names_to = "error_type", values_to = "count") %>%
mutate(error_type = factor(error_type, levels =  rev(c("Old.lemma", "Old.Rule", "Free.Var", "Over.Reg", "Over.Irreg", "Silly"))))
dat.err.long %<>%
mutate(
algorithm = if_else(str_starts(Data.set, "ru"), "rule", "neural"),
split = if_else(str_ends(Data.set, "d"), "dev", "test"),
split_set = case_when(
str_detect(Data.set, "-s-") ~ "Seg (by lemma)",
str_detect(Data.set, "-m-") ~ "Seg-Minimal (by form)",
str_detect(Data.set, "-o-") ~ "Original Split"
)
)
# Mutate to factors
dat.err.long %<>%
mutate(
algorithm = factor(algorithm, levels = c("rule", "neural"))
)
tot.errors.by.data.set <- dat.err.long %>%
group_by(Data.set) %>%
summarize(tot_error_data_set = sum(count))
dat.err.long %<>%
left_join(tot.errors.by.data.set, by = "Data.set") %>%
mutate(prop_out_of_errors_for_data_set = count/tot_error_data_set)
dat.forms.long <- dat.forms %>%
mutate(split = case_when(Data.set == "fra.trn" ~ "trn",
Data.set == "fra.dev" ~ "dev",
Data.set == "fra.tst" ~ "test")
) %>%
pivot_longer(cols = c("Original", "Segmentations", "Segmentations.Minimal"),
names_to = "split_set_raw",
values_to = "split_size"
)
# Let's also rename split_set names to be consistent with dat.err.long
dat.forms.long %<>%
mutate(split_set = case_when(split_set_raw == "Original" ~ "Original Split",
split_set_raw == "Segmentations" ~ "Seg (by lemma)",
split_set_raw == "Segmentations.Minimal" ~ "Seg-Minimal (by form)"
)
) %>%
dplyr::select(split_set, split, split_size)
dat.err.long %<>%
left_join(dat.forms.long, by = c("split", "split_set")) %>%
mutate(prop_forms_in_eval_split = count/split_size)
new_labels_algo <- c("rule" = "Nonneural (RU)", "neural" = "Neural (NN)")
new_labels_errors <-  c("Old.lemma" = "Old Lemma", "Old.Rule" = "Old Rule", "Free.Var" = "Free Var.", "Over.Reg" = "Over Reg", "Over.Irreg" = "Over Irreg", "Silly" = "Silly")
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = FALSE) + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = FALSE) + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = FALSE) + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = FALSE) + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = FALSE) + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = FALSE) + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
knitr::opts_chunk$set(fig.path = "figs/fra-", dev = c('pdf', 'png'), cache=T)
library(tidyr)
library(ggplot2)
library(magrittr)
library(dplyr)
library(stringr)
dat.forms <- read.csv("data/fra_data_set_form_counts.csv")
dat.errors <- read.csv("data/fra_error_distribution.csv")
dat.err.long <- dat.errors %>%
pivot_longer(!Data.set, names_to = "error_type", values_to = "count") %>%
mutate(error_type = factor(error_type, levels =  rev(c("Old.lemma", "Old.Rule", "Free.Var", "Over.Reg", "Over.Irreg", "Silly"))))
dat.err.long %<>%
mutate(
algorithm = if_else(str_starts(Data.set, "ru"), "rule", "neural"),
split = if_else(str_ends(Data.set, "d"), "dev", "test"),
split_set = case_when(
str_detect(Data.set, "-s-") ~ "Seg (by lemma)",
str_detect(Data.set, "-m-") ~ "Seg-Minimal (by form)",
str_detect(Data.set, "-o-") ~ "Original Split"
)
)
# Mutate to factors
dat.err.long %<>%
mutate(
algorithm = factor(algorithm, levels = c("rule", "neural"))
)
tot.errors.by.data.set <- dat.err.long %>%
group_by(Data.set) %>%
summarize(tot_error_data_set = sum(count))
dat.err.long %<>%
left_join(tot.errors.by.data.set, by = "Data.set") %>%
mutate(prop_out_of_errors_for_data_set = count/tot_error_data_set)
dat.forms.long <- dat.forms %>%
mutate(split = case_when(Data.set == "fra.trn" ~ "trn",
Data.set == "fra.dev" ~ "dev",
Data.set == "fra.tst" ~ "test")
) %>%
pivot_longer(cols = c("Original", "Segmentations", "Segmentations.Minimal"),
names_to = "split_set_raw",
values_to = "split_size"
)
# Let's also rename split_set names to be consistent with dat.err.long
dat.forms.long %<>%
mutate(split_set = case_when(split_set_raw == "Original" ~ "Original Split",
split_set_raw == "Segmentations" ~ "Seg (by lemma)",
split_set_raw == "Segmentations.Minimal" ~ "Seg-Minimal (by form)"
)
) %>%
dplyr::select(split_set, split, split_size)
dat.err.long %<>%
left_join(dat.forms.long, by = c("split", "split_set")) %>%
mutate(prop_forms_in_eval_split = count/split_size)
new_labels_algo <- c("rule" = "Nonneural (RU)", "neural" = "Neural (NN)")
new_labels_errors <-  c("Old.lemma" = "Old Lemma", "Old.Rule" = "Old Rule", "Free.Var" = "Free Var.", "Over.Reg" = "Over Reg", "Over.Irreg" = "Over Irreg", "Silly" = "Silly")
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
knitr::opts_chunk$set(fig.path = "figs/fra-", dev = c('pdf', 'png'), cache=T)
library(tidyr)
library(ggplot2)
library(magrittr)
library(dplyr)
library(stringr)
dat.forms <- read.csv("data/fra_data_set_form_counts.csv")
dat.errors <- read.csv("data/fra_error_distribution.csv")
dat.err.long <- dat.errors %>%
pivot_longer(!Data.set, names_to = "error_type", values_to = "count") %>%
mutate(error_type = factor(error_type, levels =  rev(c("Old.lemma", "Old.Rule", "Free.Var", "Over.Reg", "Over.Irreg", "Silly"))))
dat.err.long %<>%
mutate(
algorithm = if_else(str_starts(Data.set, "ru"), "rule", "neural"),
split = if_else(str_ends(Data.set, "d"), "dev", "test"),
split_set = case_when(
str_detect(Data.set, "-s-") ~ "Seg (by lemma)",
str_detect(Data.set, "-m-") ~ "Seg-Minimal (by form)",
str_detect(Data.set, "-o-") ~ "Original Split"
)
)
# Mutate to factors
dat.err.long %<>%
mutate(
algorithm = factor(algorithm, levels = c("rule", "neural"))
)
tot.errors.by.data.set <- dat.err.long %>%
group_by(Data.set) %>%
summarize(tot_error_data_set = sum(count))
dat.err.long %<>%
left_join(tot.errors.by.data.set, by = "Data.set") %>%
mutate(prop_out_of_errors_for_data_set = count/tot_error_data_set)
dat.forms.long <- dat.forms %>%
mutate(split = case_when(Data.set == "fra.trn" ~ "trn",
Data.set == "fra.dev" ~ "dev",
Data.set == "fra.tst" ~ "test")
) %>%
pivot_longer(cols = c("Original", "Segmentations", "Segmentations.Minimal"),
names_to = "split_set_raw",
values_to = "split_size"
)
# Let's also rename split_set names to be consistent with dat.err.long
dat.forms.long %<>%
mutate(split_set = case_when(split_set_raw == "Original" ~ "Original Split",
split_set_raw == "Segmentations" ~ "Seg (by lemma)",
split_set_raw == "Segmentations.Minimal" ~ "Seg-Minimal (by form)"
)
) %>%
dplyr::select(split_set, split, split_size)
dat.err.long %<>%
left_join(dat.forms.long, by = c("split", "split_set")) %>%
mutate(prop_forms_in_eval_split = count/split_size)
new_labels_algo <- c("rule" = "Nonneural (RU)", "neural" = "Neural (NN)")
new_labels_errors <-  c("Old.lemma" = "Old Lemma", "Old.Rule" = "Old Rule", "Free.Var" = "Free Var.", "Over.Reg" = "Over Reg", "Over.Irreg" = "Over Irreg", "Silly" = "Silly")
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
knitr::opts_chunk$set(fig.path = "figs/fra-", dev = c('pdf', 'png'), cache=T)
library(tidyr)
library(ggplot2)
library(magrittr)
library(dplyr)
library(stringr)
dat.forms <- read.csv("data/fra_data_set_form_counts.csv")
dat.errors <- read.csv("data/fra_error_distribution.csv")
dat.err.long <- dat.errors %>%
pivot_longer(!Data.set, names_to = "error_type", values_to = "count") %>%
mutate(error_type = factor(error_type, levels =  rev(c("Old.lemma", "Old.Rule", "Free.Var", "Over.Reg", "Over.Irreg", "Silly"))))
dat.err.long %<>%
mutate(
algorithm = if_else(str_starts(Data.set, "ru"), "rule", "neural"),
split = if_else(str_ends(Data.set, "d"), "dev", "test"),
split_set = case_when(
str_detect(Data.set, "-s-") ~ "Seg (by lemma)",
str_detect(Data.set, "-m-") ~ "Seg-Minimal (by form)",
str_detect(Data.set, "-o-") ~ "Original Split"
)
)
# Mutate to factors
dat.err.long %<>%
mutate(
algorithm = factor(algorithm, levels = c("rule", "neural"))
)
tot.errors.by.data.set <- dat.err.long %>%
group_by(Data.set) %>%
summarize(tot_error_data_set = sum(count))
dat.err.long %<>%
left_join(tot.errors.by.data.set, by = "Data.set") %>%
mutate(prop_out_of_errors_for_data_set = count/tot_error_data_set)
dat.forms.long <- dat.forms %>%
mutate(split = case_when(Data.set == "fra.trn" ~ "trn",
Data.set == "fra.dev" ~ "dev",
Data.set == "fra.tst" ~ "test")
) %>%
pivot_longer(cols = c("Original", "Segmentations", "Segmentations.Minimal"),
names_to = "split_set_raw",
values_to = "split_size"
)
# Let's also rename split_set names to be consistent with dat.err.long
dat.forms.long %<>%
mutate(split_set = case_when(split_set_raw == "Original" ~ "Original Split",
split_set_raw == "Segmentations" ~ "Seg (by lemma)",
split_set_raw == "Segmentations.Minimal" ~ "Seg-Minimal (by form)"
)
) %>%
dplyr::select(split_set, split, split_size)
dat.err.long %<>%
left_join(dat.forms.long, by = c("split", "split_set")) %>%
mutate(prop_forms_in_eval_split = count/split_size)
new_labels_algo <- c("rule" = "Nonneural (RU)", "neural" = "Neural (NN)")
new_labels_errors <-  c("Old.lemma" = "Old Lemma", "Old.Rule" = "Old Rule", "Free.Var" = "Free Var.", "Over.Reg" = "Over Reg", "Over.Irreg" = "Over Irreg", "Silly" = "Silly")
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
knitr::opts_chunk$set(fig.path = "figs/fra-", dev = c('pdf', 'png'), cache=T)
library(tidyr)
library(ggplot2)
library(magrittr)
library(dplyr)
library(stringr)
dat.forms <- read.csv("data/fra_data_set_form_counts.csv")
dat.errors <- read.csv("data/fra_error_distribution.csv")
dat.err.long <- dat.errors %>%
pivot_longer(!Data.set, names_to = "error_type", values_to = "count") %>%
mutate(error_type = factor(error_type, levels =  rev(c("Old.lemma", "Old.Rule", "Free.Var", "Over.Reg", "Over.Irreg", "Silly"))))
dat.err.long %<>%
mutate(
algorithm = if_else(str_starts(Data.set, "ru"), "rule", "neural"),
split = if_else(str_ends(Data.set, "d"), "dev", "test"),
split_set = case_when(
str_detect(Data.set, "-s-") ~ "Seg (by lemma)",
str_detect(Data.set, "-m-") ~ "Seg-Minimal (by form)",
str_detect(Data.set, "-o-") ~ "Original Split"
)
)
# Mutate to factors
dat.err.long %<>%
mutate(
algorithm = factor(algorithm, levels = c("rule", "neural"))
)
tot.errors.by.data.set <- dat.err.long %>%
group_by(Data.set) %>%
summarize(tot_error_data_set = sum(count))
dat.err.long %<>%
left_join(tot.errors.by.data.set, by = "Data.set") %>%
mutate(prop_out_of_errors_for_data_set = count/tot_error_data_set)
dat.forms.long <- dat.forms %>%
mutate(split = case_when(Data.set == "fra.trn" ~ "trn",
Data.set == "fra.dev" ~ "dev",
Data.set == "fra.tst" ~ "test")
) %>%
pivot_longer(cols = c("Original", "Segmentations", "Segmentations.Minimal"),
names_to = "split_set_raw",
values_to = "split_size"
)
# Let's also rename split_set names to be consistent with dat.err.long
dat.forms.long %<>%
mutate(split_set = case_when(split_set_raw == "Original" ~ "Original Split",
split_set_raw == "Segmentations" ~ "Seg (by lemma)",
split_set_raw == "Segmentations.Minimal" ~ "Seg-Minimal (by form)"
)
) %>%
dplyr::select(split_set, split, split_size)
dat.err.long %<>%
left_join(dat.forms.long, by = c("split", "split_set")) %>%
mutate(prop_forms_in_eval_split = count/split_size)
new_labels_algo <- c("rule" = "Nonneural (RU)", "neural" = "Neural (NN)")
new_labels_errors <-  c("Old.lemma" = "Old Lemma", "Old.Rule" = "Old Rule", "Free.Var" = "Free Var.", "Over.Reg" = "Over Reg", "Over.Irreg" = "Over Irreg", "Silly" = "Silly")
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = count, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Number of errors for algorithm and split set") +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_out_of_errors_for_data_set, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total errors for algorithm and split set", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "dev") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
dat.err.long %>%
filter(split == "test") %>%
ggplot(aes(y = prop_forms_in_eval_split, x = error_type, fill = error_type)) +
geom_bar(stat = "identity", position = "dodge") +
scale_x_discrete(name = "Error type", labels = new_labels_errors) +
scale_fill_discrete(type = "Okabe-Ito") +
scale_y_continuous(name = "Proportion of total forms in evaluation split with error", labels = scales::percent_format()) +
facet_grid(algorithm~split_set, labeller = labeller(algorithm = new_labels_algo)) + coord_flip() + guides(fill = "none") + theme_bw()
install.packages("magick")
